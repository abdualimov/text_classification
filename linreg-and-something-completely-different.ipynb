{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/class-1/class.csv\n",
      "/kaggle/input/sf-review-stars-prediction/submission.csv\n",
      "/kaggle/input/sf-review-stars-prediction/baseline.ipynb\n",
      "/kaggle/input/sf-review-stars-prediction/test.csv\n",
      "/kaggle/input/sf-review-stars-prediction/train.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ktrain\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/26/b66d9a4e27ca2854ee7f2c66084f90b7bf7e27e46b7611be52f2fe9ae5dc/ktrain-0.13.2.tar.gz (25.2MB)\r\n",
      "\u001b[K     |████████████████████████████████| 25.2MB 561kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: tensorflow==2.1.0 in /opt/conda/lib/python3.6/site-packages (from ktrain) (2.1.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.6/site-packages (from ktrain) (0.21.3)\r\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from ktrain) (3.0.3)\r\n",
      "Collecting pandas>=1.0.1\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/71/8f53bdbcbc67c912b888b40def255767e475402e9df64050019149b1a943/pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (10.0MB)\r\n",
      "\u001b[K     |████████████████████████████████| 10.0MB 35.6MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: fastprogress>=0.1.21 in /opt/conda/lib/python3.6/site-packages (from ktrain) (0.2.2)\r\n",
      "Collecting keras_bert>=0.81.0\r\n",
      "  Downloading https://files.pythonhosted.org/packages/2c/0f/cdc886c1018943ea62d3209bc964413d5aa9d0eb7e493abd8545be679294/keras-bert-0.81.0.tar.gz\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from ktrain) (2.22.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from ktrain) (0.14.1)\r\n",
      "Requirement already satisfied: langdetect in /opt/conda/lib/python3.6/site-packages (from ktrain) (1.0.7)\r\n",
      "Requirement already satisfied: jieba in /opt/conda/lib/python3.6/site-packages (from ktrain) (0.42.1)\r\n",
      "Collecting cchardet\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/c5/7e1a0d7b4afd83d6f8de794fce82820ec4c5136c6d52e14000822681a842/cchardet-2.1.6-cp36-cp36m-manylinux2010_x86_64.whl (241kB)\r\n",
      "\u001b[K     |████████████████████████████████| 245kB 29.9MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.3 in /opt/conda/lib/python3.6/site-packages (from ktrain) (2.4)\r\n",
      "Requirement already satisfied: bokeh in /opt/conda/lib/python3.6/site-packages (from ktrain) (1.4.0)\r\n",
      "Collecting seqeval\r\n",
      "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from ktrain) (20.0)\r\n",
      "Collecting tensorflow_datasets\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/f1/172770d86e8cd3b531b73ccb2ba5cf285ea78937ab857bd958a77ed247e3/tensorflow_datasets-2.1.0-py3-none-any.whl (3.1MB)\r\n",
      "\u001b[K     |████████████████████████████████| 3.1MB 36.5MB/s \r\n",
      "\u001b[?25hCollecting transformers>=2.7.0\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\r\n",
      "\u001b[K     |████████████████████████████████| 573kB 37.4MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: ipython in /opt/conda/lib/python3.6/site-packages (from ktrain) (7.11.1)\r\n",
      "Collecting syntok\r\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/36/5b423791cd877a21c2771a2b070194270f163f2969066923f89aa3099e2d/syntok-1.2.2.tar.gz\r\n",
      "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (2.1.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.1.0)\r\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.18.1)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (2.1.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.14.0)\r\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (0.33.6)\r\n",
      "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.4.1)\r\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.1.0)\r\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (3.11.2)\r\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (0.8.1)\r\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.11.2)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (0.1.8)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (3.1.0)\r\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (0.2.2)\r\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.0.8)\r\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (1.26.0)\r\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==2.1.0->ktrain) (0.9.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain) (1.1.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain) (2.4.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=3.0.0->ktrain) (2.8.1)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas>=1.0.1->ktrain) (2019.3)\r\n",
      "Requirement already satisfied: Keras in /opt/conda/lib/python3.6/site-packages (from keras_bert>=0.81.0->ktrain) (2.3.1)\r\n",
      "Collecting keras-transformer>=0.30.0\r\n",
      "  Downloading https://files.pythonhosted.org/packages/54/0c/fede535ac576c03863c44bf2e0bf051fe21f5e10103631b6b6236ae446f3/keras-transformer-0.32.0.tar.gz\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->ktrain) (1.25.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->ktrain) (2019.11.28)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->ktrain) (3.0.4)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->ktrain) (2.8)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx>=2.3->ktrain) (4.4.1)\r\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.6/site-packages (from bokeh->ktrain) (5.2)\r\n",
      "Requirement already satisfied: Jinja2>=2.7 in /opt/conda/lib/python3.6/site-packages (from bokeh->ktrain) (2.10.3)\r\n",
      "Requirement already satisfied: pillow>=4.0 in /opt/conda/lib/python3.6/site-packages (from bokeh->ktrain) (5.4.1)\r\n",
      "Requirement already satisfied: tornado>=4.3 in /opt/conda/lib/python3.6/site-packages (from bokeh->ktrain) (5.0.2)\r\n",
      "Requirement already satisfied: promise in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets->ktrain) (2.3)\r\n",
      "Requirement already satisfied: attrs>=18.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets->ktrain) (19.3.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets->ktrain) (0.3.1.1)\r\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets->ktrain) (0.18.2)\r\n",
      "Collecting tensorflow-metadata\r\n",
      "  Downloading https://files.pythonhosted.org/packages/3c/aa/c4c3c9339fbe9d46edd390789d7033b4fa89e9f566d5723576dfdd3ed18e/tensorflow_metadata-0.21.1-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from tensorflow_datasets->ktrain) (4.41.1)\r\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /opt/conda/lib/python3.6/site-packages (from transformers>=2.7.0->ktrain) (0.7)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers>=2.7.0->ktrain) (2020.1.8)\r\n",
      "Collecting tokenizers==0.5.2\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\r\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 32.6MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from transformers>=2.7.0->ktrain) (1.11.9)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers>=2.7.0->ktrain) (3.0.12)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers>=2.7.0->ktrain) (0.0.38)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (from transformers>=2.7.0->ktrain) (0.1.85)\r\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.6/site-packages (from ipython->ktrain) (4.3.3)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython->ktrain) (0.7.5)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.6/site-packages (from ipython->ktrain) (44.0.0.post20200106)\r\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.6/site-packages (from ipython->ktrain) (4.7.0)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from ipython->ktrain) (3.0.2)\r\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython->ktrain) (0.14.1)\r\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from ipython->ktrain) (2.5.2)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython->ktrain) (0.1.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.1)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.16.0)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.11.0)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications>=1.0.8->tensorflow==2.1.0->ktrain) (2.9.0)\r\n",
      "Collecting keras-pos-embd>=0.10.0\r\n",
      "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\r\n",
      "Collecting keras-multi-head>=0.22.0\r\n",
      "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\r\n",
      "Collecting keras-layer-normalization>=0.12.0\r\n",
      "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\r\n",
      "Collecting keras-position-wise-feed-forward>=0.5.0\r\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\r\n",
      "Collecting keras-embed-sim>=0.7.0\r\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=2.7->bokeh->ktrain) (1.1.1)\r\n",
      "Requirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.6/site-packages (from tensorflow-metadata->tensorflow_datasets->ktrain) (1.51.0)\r\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.9 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers>=2.7.0->ktrain) (1.14.9)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers>=2.7.0->ktrain) (0.9.4)\r\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers>=2.7.0->ktrain) (0.3.2)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers>=2.7.0->ktrain) (7.0)\r\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from traitlets>=4.2->ipython->ktrain) (0.2.0)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython->ktrain) (0.6.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ktrain) (0.1.7)\r\n",
      "Requirement already satisfied: parso>=0.5.0 in /opt/conda/lib/python3.6/site-packages (from jedi>=0.10->ipython->ktrain) (0.5.2)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (1.3.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.2.8)\r\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (4.0)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (4.0.0)\r\n",
      "Collecting keras-self-attention==0.41.0\r\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\r\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.15.0,>=1.14.9->boto3->transformers>=2.7.0->ktrain) (0.15.2)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (3.1.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0->ktrain) (0.4.8)\r\n",
      "Building wheels for collected packages: ktrain, keras-bert, seqeval, syntok, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\r\n",
      "  Building wheel for ktrain (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for ktrain: filename=ktrain-0.13.2-cp36-none-any.whl size=25239774 sha256=e5ee83cf720ad2abbf77219c54bd78cf3060fcd61a0e626306f607f3a5fa6144\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/95/fb/62/cf5424c7a9c267b78db4efacfe8b4c3a0a3f1a755f2d63e428\r\n",
      "  Building wheel for keras-bert (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-bert: filename=keras_bert-0.81.0-cp36-none-any.whl size=37913 sha256=6d3ffc1ee1c538b8a6244b62be8e8cf3671c7f6be98c7491edc03ff0ef5e5aba\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/27/da/ffc2d573aa48b87440ec4f98bc7c992e3a2d899edb2d22ef9e\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=45c0c19f6930d3a85ba61865f3e8d103c0a95c5b49f9e3e90188e3241ee8a4a8\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\r\n",
      "  Building wheel for syntok (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for syntok: filename=syntok-1.2.2-cp36-none-any.whl size=20723 sha256=750f93b6aece85f068642fd43fae11ca33dd6a5cb9d838e8472b23d4bd82b2d1\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/b4/b0/d2/ffdbbc1a16cb37e580fb7b3a6fbaaf09c7f7c163981db385b3\r\n",
      "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-transformer: filename=keras_transformer-0.32.0-cp36-none-any.whl size=13266 sha256=516c0ccdcd3d0f728d5e1bdbcf845edbc1c72e5decf1e6e14c84241f6b6be316\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/f0/ce/82fa5d024d5ef8e263f26a50dcee23820efe245680ce9c922a\r\n",
      "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7553 sha256=5529f2693b6a267414d676bbeb3a478231553a06c1949e3e28e3770da1dab36d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\r\n",
      "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=25a01037306103b6d25cfb0625125fc8609d81ea67f81c6adf26bf9f71640b76\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\r\n",
      "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=672f4378453343fe7d68124e0cc21992f4a491b730722cccfa416a135955bc7f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\r\n",
      "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5624 sha256=186b45209115e9093d613d8a7d1a004930b75be4f6cf11779bd28c5b4a67b696\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\r\n",
      "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=b7c0dd4e03273005da04bfa33ad948325db88e6913c28d4355e1d78ca68f0d32\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\r\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17290 sha256=13e01f7d4633c328ca5d03d5e12e17e67b0454b8cfeb564951839dce8bf138c5\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\r\n",
      "Successfully built ktrain keras-bert seqeval syntok keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\r\n",
      "\u001b[31mERROR: tpot 0.11.1 has requirement scikit-learn>=0.22.0, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mERROR: mizani 0.6.0 has requirement matplotlib>=3.1.1, but you'll have matplotlib 3.0.3 which is incompatible.\u001b[0m\r\n",
      "Installing collected packages: pandas, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, cchardet, seqeval, tensorflow-metadata, tensorflow-datasets, tokenizers, transformers, syntok, ktrain\r\n",
      "  Found existing installation: pandas 0.25.3\r\n",
      "    Uninstalling pandas-0.25.3:\r\n",
      "      Successfully uninstalled pandas-0.25.3\r\n",
      "  Found existing installation: transformers 2.3.0\r\n",
      "    Uninstalling transformers-2.3.0:\r\n",
      "      Successfully uninstalled transformers-2.3.0\r\n",
      "Successfully installed cchardet-2.1.6 keras-bert-0.81.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.32.0 ktrain-0.13.2 pandas-1.0.3 seqeval-0.0.12 syntok-1.2.2 tensorflow-datasets-2.1.0 tensorflow-metadata-0.21.1 tokenizers-0.5.2 transformers-2.8.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ktrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext: a fastText-like model [http://arxiv.org/pdf/1607.01759.pdf]\n",
      "logreg: logistic regression using a trainable Embedding layer\n",
      "nbsvm: NBSVM model [http://www.aclweb.org/anthology/P12-2018]\n",
      "bigru: Bidirectional GRU with pretrained fasttext word vectors [https://fasttext.cc/docs/en/crawl-vectors.html]\n",
      "standard_gru: simple 2-layer GRU with randomly initialized embeddings\n",
      "bert: Bidirectional Encoder Representations from Transformers (BERT) [https://arxiv.org/abs/1810.04805]\n",
      "distilbert: distilled, smaller, and faster BERT from Hugging Face [https://arxiv.org/abs/1910.01108]\n"
     ]
    }
   ],
   "source": [
    "text.print_text_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're using TF 2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from ast import literal_eval\n",
    "import torch\n",
    "from sklearn.cluster import DBSCAN\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "print(\"We're using TF\", tf.__version__)\n",
    "import keras\n",
    "import keras.models as M\n",
    "import keras.layers as L\n",
    "import keras.backend as K\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import models as M\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "submission = pd.read_csv('/kaggle/input/sf-review-stars-prediction/submission.csv')\n",
    "df_train = pd.read_csv('/kaggle/input/sf-review-stars-prediction/train.csv', parse_dates = True)\n",
    "df_test = pd.read_csv('/kaggle/input/sf-review-stars-prediction/test.csv', parse_dates = True)\n",
    "df_test.drop('index', axis = 1, inplace = True)\n",
    "df_train['sample'] = 1\n",
    "df_test['sample'] = 0\n",
    "df_test['overall'] = 0\n",
    "data = df_test.append(df_train, sort = False).reset_index(drop = True)\n",
    "data.drop(['Unnamed: 0', 'Unnamed: 0.1', 'ID'], axis = 1, inplace = True)\n",
    "data['reviewTime'] = pd.to_datetime(data['reviewTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([ 'asin',        'helpful', 'reviewTime',\n",
    "           'reviewerID',   'reviewerName',        'summary', 'unixReviewTime',\n",
    "             'features',], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.query('sample == 1').drop('sample', axis = 1)\n",
    "classes = ['overall_1.0', 'overall_2.0', 'overall_3.0', 'overall_4.0', 'overall_5.0']\n",
    "train_data = pd.get_dummies(train_data, columns=['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall_1.0</th>\n",
       "      <th>overall_2.0</th>\n",
       "      <th>overall_3.0</th>\n",
       "      <th>overall_4.0</th>\n",
       "      <th>overall_5.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>I enjoy vintage books and movies so I enjoyed ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>This book is a reissue of an old one; the auth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>This was a fairly interesting read.  It had ol...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>I'd never read any of the Amy Brewster mysteri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>If you like period pieces - clothing, lingo, y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>I enjoyed reading this story.  The characters ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>This was a fun book to read for the 2nd time. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Or just a Christmas romance to make you crack-...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>I read \"Stop the wedding\" by this author and w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>This was one of the funniest books I have ever...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviewText  overall_1.0  \\\n",
       "1000  I enjoy vintage books and movies so I enjoyed ...            0   \n",
       "1001  This book is a reissue of an old one; the auth...            0   \n",
       "1002  This was a fairly interesting read.  It had ol...            0   \n",
       "1003  I'd never read any of the Amy Brewster mysteri...            0   \n",
       "1004  If you like period pieces - clothing, lingo, y...            0   \n",
       "...                                                 ...          ...   \n",
       "1995  I enjoyed reading this story.  The characters ...            0   \n",
       "1996  This was a fun book to read for the 2nd time. ...            0   \n",
       "1997  Or just a Christmas romance to make you crack-...            0   \n",
       "1998  I read \"Stop the wedding\" by this author and w...            1   \n",
       "1999  This was one of the funniest books I have ever...            0   \n",
       "\n",
       "      overall_2.0  overall_3.0  overall_4.0  overall_5.0  \n",
       "1000            0            0            0            1  \n",
       "1001            0            0            1            0  \n",
       "1002            0            0            1            0  \n",
       "1003            0            0            0            1  \n",
       "1004            0            0            1            0  \n",
       "...           ...          ...          ...          ...  \n",
       "1995            0            0            0            1  \n",
       "1996            0            0            1            0  \n",
       "1997            0            0            0            1  \n",
       "1998            0            0            0            0  \n",
       "1999            0            0            0            1  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading pretrained BERT model (uncased_L-12_H-768_A-12.zip)...\n",
      "[██████████████████████████████████████████████████]\n",
      "extracting pretrained BERT model...\n",
      "done.\n",
      "\n",
      "cleanup downloaded zip...\n",
      "done.\n",
      "\n",
      "preprocessing train...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: en\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "done."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test), preproc = text.texts_from_df(train_df=train_data, \n",
    "                                                                   text_column='reviewText',\n",
    "                                                                   label_columns=classes,\n",
    "                                                                   val_pct=0.15, \n",
    "                                                                   max_features=20000, \n",
    "                                                                   maxlen=200,\n",
    "                                                                   preprocess_mode='bert',\n",
    "                                                                   ngram_range=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "maxlen is 200\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "model = text.text_classifier('bert', (x_train, y_train), preproc=preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ktrain.get_learner(model, train_data=(x_train, y_train), val_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using triangular learning rate policy with max lr of 1e-05...\n",
      "Train on 850 samples, validate on 150 samples\n",
      "Epoch 1/6\n",
      "850/850 [==============================] - 31s 37ms/sample - loss: 1.2998 - acc: 0.4753 - val_loss: 1.2311 - val_acc: 0.5467\n",
      "Epoch 2/6\n",
      "850/850 [==============================] - 21s 24ms/sample - loss: 1.1865 - acc: 0.5000 - val_loss: 1.1464 - val_acc: 0.5733\n",
      "Epoch 3/6\n",
      "850/850 [==============================] - 21s 24ms/sample - loss: 1.1051 - acc: 0.5212 - val_loss: 1.0837 - val_acc: 0.6000\n",
      "Epoch 4/6\n",
      "850/850 [==============================] - 21s 24ms/sample - loss: 1.0333 - acc: 0.5659 - val_loss: 1.0832 - val_acc: 0.5867\n",
      "Epoch 5/6\n",
      "850/850 [==============================] - 21s 24ms/sample - loss: 0.9395 - acc: 0.6153 - val_loss: 1.0250 - val_acc: 0.6067\n",
      "Epoch 6/6\n",
      "850/850 [==============================] - 21s 24ms/sample - loss: 0.8558 - acc: 0.6494 - val_loss: 1.0090 - val_acc: 0.5733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efd2c42ce80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.autofit(1e-5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.query('sample == 0').drop(['sample', 'overall'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict = predictor.predict(test_data['reviewText'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    726\n",
       "4.0    185\n",
       "3.0     87\n",
       "2.0      2\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('/kaggle/input/sf-review-stars-prediction/test.csv')\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_df.ID,\n",
    "    'overall': predict\n",
    "})\n",
    "submission['overall'] = submission['overall'].apply(lambda x: x[-3:])\n",
    "submission.to_csv('submission.csv', index=None)\n",
    "submission.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
